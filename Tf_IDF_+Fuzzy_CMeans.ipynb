{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4i0o1Ma4Xu5N"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import gensim\n",
        "#import contractions\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from sklearn.cluster import KMeans\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn import cluster\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.manifold import TSNE\n",
        "from nltk.cluster import KMeansClusterer, euclidean_distance\n",
        "import nltk\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.cluster import DBSCAN\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "from nltk.tokenize import wordpunct_tokenize\n",
        "from sklearn.metrics import silhouette_score\n",
        "import matplotlib.pyplot as plt\n",
        "#import flair\n",
        "from scipy.spatial import distance\n",
        "#from simpletransformers.language_representation import RepresentationModel\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "#import umap.umap_ as umap\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from sklearn.metrics import silhouette_score\n",
        "from wordcloud import WordCloud\n",
        "#import texthero as hero\n",
        "from sklearn import metrics\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0Zx9V5UYjPN",
        "outputId": "cfd33fea-f98b-42a3-b42d-f6f54b0ade08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.0.tar.gz (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 2.4 MB/s \n",
            "\u001b[?25hCollecting transformers<5.0.0,>=4.6.0\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 14.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.64.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.12.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 38.8 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (4.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.7.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.11.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.12.20)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 48.6 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 49.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.0-py3-none-any.whl size=120747 sha256=af227153fd5bf70f0f1785f2620c0efa6bb42c0ba6af0f16da45d29a4d197fe6\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/c0/df/b6873ab7aac3f2465aa9144b6b4c41c4391cfecc027c8b07e7\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers, sentencepiece, sentence-transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 sentence-transformers-2.2.0 sentencepiece-0.1.96 tokenizers-0.12.1 transformers-4.19.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting contractions\n",
            "  Downloading contractions-0.1.72-py2.py3-none-any.whl (8.3 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.21-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting anyascii\n",
            "  Downloading anyascii-0.3.1-py3-none-any.whl (287 kB)\n",
            "\u001b[K     |████████████████████████████████| 287 kB 34.1 MB/s \n",
            "\u001b[?25hCollecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 71.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.1 contractions-0.1.72 pyahocorasick-1.4.4 textsearch-0.0.21\n"
          ]
        }
      ],
      "source": [
        "!pip install -U sentence-transformers\n",
        "#!pip install \"gensim==3.8.1\"\n",
        "#!pip install texthero\n",
        "!pip install contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWTAmK5_Yjky",
        "outputId": "bca98516-0539-4b6b-8079-34618efab577"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQp0qv7PYjxl"
      },
      "outputs": [],
      "source": [
        "data_train=pd.read_csv('/content/drive/MyDrive/BBC News Train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FL4lfnhJaMKQ"
      },
      "outputs": [],
      "source": [
        "data_train.drop(['ArticleId'],inplace=True,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VBManrYaMQs",
        "outputId": "5d24ecea-bfc8-4574-f441-7696f733a5e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input features shape: (1490, 24746)\n",
            "\n",
            "Take a look at the features extracted from the first news article:\n",
            "[[0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "vec = TfidfVectorizer()\n",
        "features= vec.fit_transform(data_train['Text'])\n",
        "print(\"Input features shape:\", features.shape)\n",
        "print(f\"\\nTake a look at the features extracted from the first news article:\\n{features[0].toarray()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWvjehHPaMS-",
        "outputId": "74e75582-5b39-431f-ca88-92372edbd3d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fuzzy-c-means\n",
            "  Downloading fuzzy_c_means-1.6.3-py3-none-any.whl (9.1 kB)\n",
            "Collecting pydantic<2.0.0,>=1.8.2\n",
            "  Downloading pydantic-1.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.1 MB 36.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from fuzzy-c-means) (1.21.6)\n",
            "Requirement already satisfied: tabulate<0.9.0,>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from fuzzy-c-means) (0.8.9)\n",
            "Collecting typer<0.4.0,>=0.3.2\n",
            "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic<2.0.0,>=1.8.2->fuzzy-c-means) (4.2.0)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.2->fuzzy-c-means) (7.1.2)\n",
            "Installing collected packages: typer, pydantic, fuzzy-c-means\n",
            "Successfully installed fuzzy-c-means-1.6.3 pydantic-1.9.1 typer-0.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install fuzzy-c-means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lpXKmKYaMVt"
      },
      "outputs": [],
      "source": [
        "from fcmeans import FCM\n",
        "features=features.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2e0tw2haMXX"
      },
      "outputs": [],
      "source": [
        "my_model = FCM(n_clusters=5,random_state=42) \n",
        "my_model.fit(features)\n",
        "data_train['cluster']=my_model.predict(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3a0EFoeaMZ9",
        "outputId": "0baacdcd-a228-4f91-90e9-72045f9d5500"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "business:\n",
            " Top cluster number: 2, Number of samples: 168\n",
            "tech:\n",
            " Top cluster number: 4, Number of samples: 92\n",
            "politics:\n",
            " Top cluster number: 1, Number of samples: 240\n",
            "sport:\n",
            " Top cluster number: 2, Number of samples: 298\n",
            "entertainment:\n",
            " Top cluster number: 2, Number of samples: 237\n",
            "\n",
            "Map cluster number to category:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{1: 'politics', 2: 'entertainment', 4: 'tech'}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cluster_to_category = {}\n",
        "for cat in data_train['Category'].unique():\n",
        "    mark = data_train['Category'] == cat\n",
        "    top = data_train[mark]['cluster'].value_counts().head(1)\n",
        "    count = top.values[0]\n",
        "    cluster = top.index[0]\n",
        "    print(f\"{cat}:\\n Top cluster number: {cluster}, Number of samples: {count}\")\n",
        "    cluster_to_category[cluster] = cat\n",
        "\n",
        "print(\"\\nMap cluster number to category:\")\n",
        "cluster_to_category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "XelPMWimaMbr",
        "outputId": "31eb6a36-f8bc-4cb4-f9df-141e72b7a095"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-37938525-b33a-4535-b864-51a75ad4c106\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Category</th>\n",
              "      <th>cluster</th>\n",
              "      <th>clustered_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
              "      <td>business</td>\n",
              "      <td>2</td>\n",
              "      <td>entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>german business confidence slides german busin...</td>\n",
              "      <td>business</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
              "      <td>business</td>\n",
              "      <td>4</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
              "      <td>tech</td>\n",
              "      <td>4</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
              "      <td>business</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>howard  truanted to play snooker  conservative...</td>\n",
              "      <td>politics</td>\n",
              "      <td>2</td>\n",
              "      <td>entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>wales silent on grand slam talk rhys williams ...</td>\n",
              "      <td>sport</td>\n",
              "      <td>2</td>\n",
              "      <td>entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>french honour for director parker british film...</td>\n",
              "      <td>entertainment</td>\n",
              "      <td>2</td>\n",
              "      <td>entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>car giant hit by mercedes slump a slump in pro...</td>\n",
              "      <td>business</td>\n",
              "      <td>2</td>\n",
              "      <td>entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>fockers fuel festive film chart comedy meet th...</td>\n",
              "      <td>entertainment</td>\n",
              "      <td>2</td>\n",
              "      <td>entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>blair rejects iraq advice calls tony blair has...</td>\n",
              "      <td>politics</td>\n",
              "      <td>1</td>\n",
              "      <td>politics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>housewives lift channel 4 ratings the debut of...</td>\n",
              "      <td>entertainment</td>\n",
              "      <td>2</td>\n",
              "      <td>entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>uk coal plunges into deeper loss shares in uk ...</td>\n",
              "      <td>business</td>\n",
              "      <td>2</td>\n",
              "      <td>entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>bp surges ahead on high oil price oil giant bp...</td>\n",
              "      <td>business</td>\n",
              "      <td>2</td>\n",
              "      <td>entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>ireland 21-19 argentina an injury-time dropped...</td>\n",
              "      <td>sport</td>\n",
              "      <td>2</td>\n",
              "      <td>entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>wenger signs new deal arsenal manager arsene w...</td>\n",
              "      <td>sport</td>\n",
              "      <td>2</td>\n",
              "      <td>entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>u2 s desire to be number one u2  who have won ...</td>\n",
              "      <td>entertainment</td>\n",
              "      <td>1</td>\n",
              "      <td>politics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>hantuchova in dubai last eight daniela hantuch...</td>\n",
              "      <td>sport</td>\n",
              "      <td>2</td>\n",
              "      <td>entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>melzer shocks agassi in san jose second seed a...</td>\n",
              "      <td>sport</td>\n",
              "      <td>2</td>\n",
              "      <td>entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>moving mobile improves golf swing a mobile pho...</td>\n",
              "      <td>tech</td>\n",
              "      <td>2</td>\n",
              "      <td>entertainment</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37938525-b33a-4535-b864-51a75ad4c106')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-37938525-b33a-4535-b864-51a75ad4c106 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-37938525-b33a-4535-b864-51a75ad4c106');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                 Text       Category  cluster  \\\n",
              "0   worldcom ex-boss launches defence lawyers defe...       business        2   \n",
              "1   german business confidence slides german busin...       business        3   \n",
              "2   bbc poll indicates economic gloom citizens in ...       business        4   \n",
              "3   lifestyle  governs mobile choice  faster  bett...           tech        4   \n",
              "4   enron bosses in $168m payout eighteen former e...       business        0   \n",
              "5   howard  truanted to play snooker  conservative...       politics        2   \n",
              "6   wales silent on grand slam talk rhys williams ...          sport        2   \n",
              "7   french honour for director parker british film...  entertainment        2   \n",
              "8   car giant hit by mercedes slump a slump in pro...       business        2   \n",
              "9   fockers fuel festive film chart comedy meet th...  entertainment        2   \n",
              "10  blair rejects iraq advice calls tony blair has...       politics        1   \n",
              "11  housewives lift channel 4 ratings the debut of...  entertainment        2   \n",
              "12  uk coal plunges into deeper loss shares in uk ...       business        2   \n",
              "13  bp surges ahead on high oil price oil giant bp...       business        2   \n",
              "14  ireland 21-19 argentina an injury-time dropped...          sport        2   \n",
              "15  wenger signs new deal arsenal manager arsene w...          sport        2   \n",
              "16  u2 s desire to be number one u2  who have won ...  entertainment        1   \n",
              "17  hantuchova in dubai last eight daniela hantuch...          sport        2   \n",
              "18  melzer shocks agassi in san jose second seed a...          sport        2   \n",
              "19  moving mobile improves golf swing a mobile pho...           tech        2   \n",
              "\n",
              "   clustered_category  \n",
              "0       entertainment  \n",
              "1                 NaN  \n",
              "2                tech  \n",
              "3                tech  \n",
              "4                 NaN  \n",
              "5       entertainment  \n",
              "6       entertainment  \n",
              "7       entertainment  \n",
              "8       entertainment  \n",
              "9       entertainment  \n",
              "10           politics  \n",
              "11      entertainment  \n",
              "12      entertainment  \n",
              "13      entertainment  \n",
              "14      entertainment  \n",
              "15      entertainment  \n",
              "16           politics  \n",
              "17      entertainment  \n",
              "18      entertainment  \n",
              "19      entertainment  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_train['clustered_category'] = data_train['cluster'].map(cluster_to_category)\n",
        "data_train.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMmzsB2naMd-",
        "outputId": "5a5535e0-0a15-44b0-9d4e-b7290909c16e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall accuracy of clustered categories: 0.3818791946308725\n"
          ]
        }
      ],
      "source": [
        "print('Overall accuracy of clustered categories:', np.mean(data_train['Category'] == data_train['clustered_category']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0T0Nu2VVz-Ie",
        "outputId": "5e0abc12-0a4f-4137-b456-5b6e47b0bd8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Silhouette Coefficient: -0.004\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "print(\"Silhouette Coefficient: %0.3f\"% metrics.silhouette_score(features,data_train['cluster']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVqwmoYFdu4P"
      },
      "source": [
        "#Tf-Idf Preprocessed Data +C-means\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ng5XvC3haMgs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import gensim\n",
        "import contractions\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from sklearn.cluster import KMeans\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn import cluster\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "from nltk.cluster import KMeansClusterer, euclidean_distance\n",
        "import nltk\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.cluster import DBSCAN\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "from nltk.tokenize import wordpunct_tokenize\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkiSdDyiaMjt",
        "outputId": "09dd1629-9222-42af-b28e-d6ca8704f979"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords') \n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "data_train=pd.read_csv('/content/drive/MyDrive/BBC News Train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsJyRYcGaMmh"
      },
      "outputs": [],
      "source": [
        "STOPWORDS = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "data_train.drop(['ArticleId'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9i4Ytw9yaMp2"
      },
      "outputs": [],
      "source": [
        "def expand_contractions(text):\n",
        "    expanded_words = []    \n",
        "    for word in text.split():\n",
        "        expanded_words.append(contractions.fix(word))   \n",
        "    expanded_text = ' '.join(expanded_words)\n",
        "    return expanded_text\n",
        " \n",
        "def remove_stopwords(text):\n",
        "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
        "def remove_digits(text):\n",
        "    return \" \".join([word for word in str(text).split() if not(word.isdigit())])\n",
        "def remove_shorttokens(text):\n",
        "    return \" \".join([word for word in str(text).split() if len(word)>1])\n",
        "def lemmatize_words(text):\n",
        "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
        "#convert it to string\n",
        "data_train[\"Text\"]=data_train[\"Text\"].astype(str)\n",
        "#Convert to lower and strip\n",
        "data_train[\"Text\"]=data_train[\"Text\"].str.lower().str.strip()\n",
        "#apply contractions\n",
        "data_train[\"Text\"]=data_train[\"Text\"].apply(lambda x:expand_contractions(x))\n",
        "#remove punctuations\n",
        "data_train[\"Text\"]=data_train[\"Text\"].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '' , x))\n",
        "#remove stop words\n",
        "data_train[\"Text\"]=data_train[\"Text\"].apply(lambda x: remove_stopwords(x))\n",
        "#Lemmatize the sentence\n",
        "data_train[\"Text\"]=data_train[\"Text\"].apply(lambda text: lemmatize_words(text))\n",
        "data_train[\"Text\"]=data_train[\"Text\"].apply(lambda text:remove_digits(text))\n",
        "data_train[\"Text\"]=data_train[\"Text\"].apply(lambda text:remove_shorttokens(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ7pkhaGeyq_",
        "outputId": "0c4ecb7b-0337-4b8b-a7b9-87f67426be25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input features shape: (1490, 23815)\n",
            "\n",
            "Take a look at the features extracted from the first news article:\n",
            "[[0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "vec = TfidfVectorizer()\n",
        "features= vec.fit_transform(data_train['Text'])\n",
        "print(\"Input features shape:\", features.shape)\n",
        "print(f\"\\nTake a look at the features extracted from the first news article:\\n{features[0].toarray()}\")\n",
        "features=features.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gtDI6tWeyt_"
      },
      "outputs": [],
      "source": [
        "my_model = FCM(n_clusters=5,random_state=42) \n",
        "my_model.fit(features)\n",
        "data_train['cluster']=my_model.predict(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4vEO1xWeyxm",
        "outputId": "93c0975f-34bc-4dbe-b766-6f530748f9a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "business:\n",
            " Top cluster number: 4, Number of samples: 179\n",
            "tech:\n",
            " Top cluster number: 2, Number of samples: 179\n",
            "politics:\n",
            " Top cluster number: 1, Number of samples: 228\n",
            "sport:\n",
            " Top cluster number: 2, Number of samples: 345\n",
            "entertainment:\n",
            " Top cluster number: 2, Number of samples: 261\n",
            "\n",
            "Map cluster number to category:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{1: 'politics', 2: 'entertainment', 4: 'business'}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cluster_to_category = {}\n",
        "for cat in data_train['Category'].unique():\n",
        "    mark = data_train['Category'] == cat\n",
        "    top = data_train[mark]['cluster'].value_counts().head(1)\n",
        "    count = top.values[0]\n",
        "    cluster = top.index[0]\n",
        "    print(f\"{cat}:\\n Top cluster number: {cluster}, Number of samples: {count}\")\n",
        "    cluster_to_category[cluster] = cat\n",
        "\n",
        "print(\"\\nMap cluster number to category:\")\n",
        "cluster_to_category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjFTzJyMeyz5",
        "outputId": "10d03096-0af2-4eda-e59e-0e31096ff911"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall accuracy of clustered categories: 0.4483221476510067\n"
          ]
        }
      ],
      "source": [
        "data_train['clustered_category'] = data_train['cluster'].map(cluster_to_category)\n",
        "print('Overall accuracy of clustered categories:', np.mean(data_train['Category'] == data_train['clustered_category']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8CqsEcZ0r0W",
        "outputId": "e88f3349-b3d6-42a7-80da-304b62daa9b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Silhouette Coefficient: 0.004\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "print(\"Silhouette Coefficient: %0.3f\"% metrics.silhouette_score(features,data_train['cluster']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_MhVAh9fsZj"
      },
      "source": [
        "#Experiment with PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "Ksv7yJxBey24",
        "outputId": "4bfa108e-8e75-4b03-af0f-78dc29ca88cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cumulative variance explained by 1490 principal components: 100.00%\n",
            "Cumulative variance explained by 1440 principal components: 100.00%\n",
            "Cumulative variance explained by 1390 principal components: 99.82%\n",
            "Cumulative variance explained by 1340 principal components: 99.07%\n",
            "Cumulative variance explained by 1290 principal components: 98.10%\n",
            "Cumulative variance explained by 1240 principal components: 97.00%\n",
            "Cumulative variance explained by 1190 principal components: 95.53%\n",
            "Cumulative variance explained by 1140 principal components: 94.11%\n",
            "Cumulative variance explained by 1090 principal components: 92.57%\n",
            "Cumulative variance explained by 1040 principal components: 90.91%\n",
            "Cumulative variance explained by 990 principal components: 89.11%\n",
            "Cumulative variance explained by 940 principal components: 87.19%\n",
            "Cumulative variance explained by 890 principal components: 85.15%\n",
            "Cumulative variance explained by 840 principal components: 82.96%\n",
            "Cumulative variance explained by 790 principal components: 80.64%\n",
            "Cumulative variance explained by 740 principal components: 78.19%\n",
            "Cumulative variance explained by 690 principal components: 75.58%\n",
            "Cumulative variance explained by 640 principal components: 72.82%\n",
            "Cumulative variance explained by 590 principal components: 69.91%\n",
            "Cumulative variance explained by 540 principal components: 66.83%\n",
            "Cumulative variance explained by 490 principal components: 63.56%\n",
            "Cumulative variance explained by 440 principal components: 60.10%\n",
            "Cumulative variance explained by 390 principal components: 56.43%\n",
            "Cumulative variance explained by 340 principal components: 52.48%\n",
            "Cumulative variance explained by 290 principal components: 48.20%\n",
            "Cumulative variance explained by 240 principal components: 43.51%\n",
            "Cumulative variance explained by 190 principal components: 38.31%\n",
            "Cumulative variance explained by 140 principal components: 32.76%\n",
            "Cumulative variance explained by 90 principal components: 25.57%\n",
            "Cumulative variance explained by 40 principal components: 16.03%\n"
          ]
        }
      ],
      "source": [
        "data_embbedding=features\n",
        "x=[]\n",
        "y=[]\n",
        "for i in range(1490,0,-50):\n",
        "  pca_2 = PCA(n_components=i)\n",
        "  pca_2_result = pca_2.fit_transform(data_embbedding)\n",
        "  x.append(i)\n",
        "  y.append(round(np.sum(pca_2.explained_variance_ratio_),2))\n",
        "  print('Cumulative variance explained by {} principal components: {:.2%}'.format(i,np.sum(pca_2.explained_variance_ratio_)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkZKznACey4J"
      },
      "outputs": [],
      "source": [
        "#95%,90%,85% covaience-->1160,1020,885\n",
        "vec_95 = TfidfVectorizer(\n",
        "        max_df=0.5,\n",
        "        min_df=2,\n",
        "        stop_words=\"english\",\n",
        "        max_features=1160,\n",
        "        use_idf=True\n",
        "    )\n",
        "vec_90 = TfidfVectorizer(\n",
        "        max_df=0.5,\n",
        "        min_df=2,\n",
        "        stop_words=\"english\",\n",
        "        max_features=1020,\n",
        "        use_idf=True\n",
        "    )\n",
        "vec_85 = TfidfVectorizer(\n",
        "        max_df=0.5,\n",
        "        min_df=2,\n",
        "        stop_words=\"english\",\n",
        "        max_features=885,\n",
        "        use_idf=True\n",
        "    )\n",
        "features95= vec_95.fit_transform(data_train['Text'])\n",
        "features90=vec_90.fit_transform(data_train['Text'])\n",
        "features85=vec_85.fit_transform(data_train['Text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBzWk8Xvey69"
      },
      "outputs": [],
      "source": [
        "features95=features95.toarray()\n",
        "features90=features90.toarray()\n",
        "features85=features85.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sl90WBYbey9Z"
      },
      "outputs": [],
      "source": [
        "my_model95= FCM(n_clusters=5,random_state=42) \n",
        "my_model95.fit(features95)\n",
        "data_train['cluster95']=my_model95.predict(features95)\n",
        "\n",
        "my_model90= FCM(n_clusters=5,random_state=42) \n",
        "my_model90.fit(features90)\n",
        "data_train['cluster90']=my_model90.predict(features90)\n",
        "\n",
        "my_model85= FCM(n_clusters=5,random_state=42) \n",
        "my_model85.fit(features85)\n",
        "data_train['cluster85']=my_model85.predict(features85)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-mgiAe-ey_1",
        "outputId": "7cb1f7fd-3778-4f27-a74f-2143eb3cb887"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "business:\n",
            " Top cluster number: 4, Number of samples: 317\n",
            "tech:\n",
            " Top cluster number: 4, Number of samples: 150\n",
            "politics:\n",
            " Top cluster number: 1, Number of samples: 236\n",
            "sport:\n",
            " Top cluster number: 2, Number of samples: 345\n",
            "entertainment:\n",
            " Top cluster number: 2, Number of samples: 252\n",
            "\n",
            "Map cluster number to category:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{1: 'politics', 2: 'entertainment', 4: 'tech'}"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cluster_to_category95= {}\n",
        "for cat in data_train['Category'].unique():\n",
        "    mark = data_train['Category'] == cat\n",
        "    top = data_train[mark]['cluster95'].value_counts().head(1)\n",
        "    count = top.values[0]\n",
        "    cluster = top.index[0]\n",
        "    print(f\"{cat}:\\n Top cluster number: {cluster}, Number of samples: {count}\")\n",
        "    cluster_to_category95[cluster] = cat\n",
        "\n",
        "print(\"\\nMap cluster number to category:\")\n",
        "cluster_to_category95"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNnoQuyKezCN",
        "outputId": "de1495e1-7208-4a41-a8fd-6fe8e9ebe65b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall accuracy of clustered categories: 0.37919463087248323\n"
          ]
        }
      ],
      "source": [
        "data_train['clustered_category95'] = data_train['cluster'].map(cluster_to_category95)\n",
        "print('Overall accuracy of clustered categories:', np.mean(data_train['Category'] == data_train['clustered_category95']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flawdlAo2qAH",
        "outputId": "1b07aaf0-9411-4679-a1cf-8cac2f848b9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Silhouette Coefficient: 0.010\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "print(\"Silhouette Coefficient: %0.3f\"% metrics.silhouette_score(features95,data_train['cluster95']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wo1E8t8tezFj",
        "outputId": "e8b1b6ef-bb68-41c6-ec8b-e751c00dac6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "business:\n",
            " Top cluster number: 4, Number of samples: 319\n",
            "tech:\n",
            " Top cluster number: 4, Number of samples: 149\n",
            "politics:\n",
            " Top cluster number: 1, Number of samples: 237\n",
            "sport:\n",
            " Top cluster number: 2, Number of samples: 344\n",
            "entertainment:\n",
            " Top cluster number: 2, Number of samples: 252\n",
            "\n",
            "Map cluster number to category:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{1: 'politics', 2: 'entertainment', 4: 'tech'}"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cluster_to_category90= {}\n",
        "for cat in data_train['Category'].unique():\n",
        "    mark = data_train['Category'] == cat\n",
        "    top = data_train[mark]['cluster90'].value_counts().head(1)\n",
        "    count = top.values[0]\n",
        "    cluster = top.index[0]\n",
        "    print(f\"{cat}:\\n Top cluster number: {cluster}, Number of samples: {count}\")\n",
        "    cluster_to_category90[cluster] = cat\n",
        "\n",
        "print(\"\\nMap cluster number to category:\")\n",
        "cluster_to_category90"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Px_uzGmjezIG",
        "outputId": "fff3475f-515c-43f4-b144-99641643089e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall accuracy of clustered categories: 0.37919463087248323\n"
          ]
        }
      ],
      "source": [
        "data_train['clustered_category90'] = data_train['cluster'].map(cluster_to_category90)\n",
        "print('Overall accuracy of clustered categories:', np.mean(data_train['Category'] == data_train['clustered_category90']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwUTgfLg3BDs",
        "outputId": "57fca884-2db5-4f8d-9058-4035adff1819"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Silhouette Coefficient: 0.009\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "print(\"Silhouette Coefficient: %0.3f\"% metrics.silhouette_score(features90,data_train['cluster90']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_E1-ZVXoezK-",
        "outputId": "8bedff7c-e316-487d-f8b2-04f33975346f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "business:\n",
            " Top cluster number: 4, Number of samples: 317\n",
            "tech:\n",
            " Top cluster number: 4, Number of samples: 149\n",
            "politics:\n",
            " Top cluster number: 1, Number of samples: 239\n",
            "sport:\n",
            " Top cluster number: 2, Number of samples: 344\n",
            "entertainment:\n",
            " Top cluster number: 2, Number of samples: 250\n",
            "\n",
            "Map cluster number to category:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{1: 'politics', 2: 'entertainment', 4: 'tech'}"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cluster_to_category85= {}\n",
        "for cat in data_train['Category'].unique():\n",
        "    mark = data_train['Category'] == cat\n",
        "    top = data_train[mark]['cluster85'].value_counts().head(1)\n",
        "    count = top.values[0]\n",
        "    cluster = top.index[0]\n",
        "    print(f\"{cat}:\\n Top cluster number: {cluster}, Number of samples: {count}\")\n",
        "    cluster_to_category85[cluster] = cat\n",
        "\n",
        "print(\"\\nMap cluster number to category:\")\n",
        "cluster_to_category85"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7APftj29ezNy",
        "outputId": "1da80056-b0df-4bf7-e0ad-b8431582b643"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall accuracy of clustered categories: 0.37919463087248323\n"
          ]
        }
      ],
      "source": [
        "data_train['clustered_category85'] = data_train['cluster'].map(cluster_to_category85)\n",
        "print('Overall accuracy of clustered categories:', np.mean(data_train['Category'] == data_train['clustered_category85']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhgDpctL3JHv",
        "outputId": "d8b8d016-3507-4b13-88a6-5f45701e5cc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Silhouette Coefficient: 0.010\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "print(\"Silhouette Coefficient: %0.3f\"% metrics.silhouette_score(features85,data_train['cluster85']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ci6_g6oyezQD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrH31AL1ezS8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8U4Y7oAezVQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fucSYBrnezZk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcz9bRuaezci"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4ZcvA6yezgL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}